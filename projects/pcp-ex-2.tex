\documentclass{article}

\input{usepackage.tex}
\input{newcommands.tex}

\title{PCP - Huji Course, Ex 2.} 
\author{David Ponarovsky}
%\abstract{We propose a new simple construction based on Tanner Codes, which yields a good LDPC testable code.} 

\newcommand{\FF}{\mathbb{F}_{q}}
\newcommand{\Chi}[1]{\chi_{ \left\{ #1  \right\} } }
\begin{document}
\maketitle

\section{Ex 1. Sumchecking with coefficients.}

We would like to verify that a given polynomial box $P$ satisfies that $ \sum_{x\in [d]^{m}}{ \varphi\left( x \right) f_{P}\left( x \right) } = 0 $  by accessing to at most $O\left(md\right)$ variables. For any function $\varphi : [d]^{m} \rightarrow \FF$. Denote by $\varphi^{\prime} : \FF^{m} \rightarrow \FF$ the extension of $\varphi$ into a polynomial over $\FF^{m}$. We saw in that lectures (and also in the previews assignment) that there is such a uinq extension. 

We are going to split the section into three, first we are going to show how to verify that $\sum_{x \in [d]^{m}}{ f_{P}\left( x \right) } = 0 $. When the polynomial is a function into $\FF$. ( I think, but not sure, that in the lecture we saw only the case when $q = 2$ ). Then in the second part we will show how can one redact the coefficients case into the non-coefficients case. Finally, in the last part, we combine all together to show that the construction achieve the requirements. 

\subsection{Over non binary field. } Let's define a series of polynomial boxes $f_{i}$ such that: 

\begin{equation*}
  \begin{split}
    f_{0} & = f \\ 
  f_{i+1} \left( x_{1}, .. , x_{m-i} \right) & = \sum_{y \in [d] } f_{i}\left(x_{1}, .. , x_{m-i}, x_{m-i+1} = y \right)
  \end{split}
\end{equation*}
Our verifier will ask for a proof which is a list of $f_{0}, f_{1}, f_{2} .., f_{m}$. Now, notice that if $f$ is an honest assignment then $f_{m}$ is just the summation of $f$ over the cube $[d]^{m}$. So it sufficient to show the existences of verifier that reject with heigh probability any string far from been encoded by the previews structure.

\begin{algorithm}[H]
  Sample uniformly random $i \sim [m]$ and check that $f_{i}$ is a codeword of the polynomial code in $m$ variables at degree at most $m\cdot d$.  
    
    $r_{1}, r_{2} .., r_{m} \leftarrow$ sample uniformly  $m$ points of $[d]$ \\
    \For{$ i \in [1,m]$} {
      Check if $f_{i+1}\left( r_{1} , .., r_{m-i-1}, x_{m-i} \right) - \sum_{y \in [d]}{f_{i} \left( r_{1}, r_{2}, .., r_{m-i-1},x_{m-i}, y \right)} $ is the zero polynomial by a random test that uses at most single query. (Here $x_{m-i} \in [d]$ is the only variable)  \\
      \ \\
      If not then reject.  
    }
    Accept if $f_{_0} = 0 $  
\end{algorithm}

\begin{proof} For convenient let's denote by $g_{i}\left( x_{m-i} \right)$ the difference that been queried in line number $3$. 
  \begin{enumerate}
    \item Correctness. Easy. If the assignment is honest then by definition $g_{i} = 0$ for any $i \in [m]$ and therefore for any $x_{m-i}$ we will have that $g_{i} \left( x_{m-i} \right) = 0$. So, in that case iteration will pass. And whole proof will be aspected  with probability $1$.  
    \item Soundness. Assume that there is   any $\deg f_{i+1}  \le \deg f_{i}$, Thus asking 
  \end{enumerate}
\end{proof}

\subsection{ Coefficients $\mapsto$ non-coefficients. }
Now as we proved in the classes $\deg f \cdot g \le \deg f + \deg g$. Therefore we can redact  the problem of verifying whether the weight summation is zero by considering the summation of the polynomial $\varphi^{\prime} \cdot f$ over the cube $[d]^{m}$. 


\begin{algorithm}[H]
  Sample uniformly random $x \sim  [d]^{m}$ and check that $\varphi^{\prime}\left( x \right) = \varphi\left( x \right)$   \\
  Check that $\varphi$ is a polynomial at degree at most $d\cdot m$. \\
  If both of the checks passed, accept. 
\end{algorithm}

\begin{proof}
\end{proof}

\subsection{Combine all.}
\begin{algorithm}[H]
  Use the first tester to check the validity of the pair $\left(\varphi^{\prime},\varphi\right)$. \\
  Check that the degree of $\xi$ is at most $2md$ \\ 
  Check that the polynomial $f\cdot \varphi^{\prime} - \xi$ is the zero polynomial. \\
  Using the first verifier, accept if the summation of $\xi$ overt the cube $[d]^{m}$ is zero.  
\end{algorithm}

\begin{proof}
\end{proof}

\section{Ex 2.}
The question concerns with the following test: \ctt{rewrite again.}

\begin{algorithm}[H]
  Choose $x,y \in \{\pm1\}^{k}$ independently. \\
  Choose $\mu \in \{\pm\}$. \\ 
  Choose a random noise $z \in \{\pm\}^{k}$ such that $z_{i}$ gets $+1$ with probability $1-\varepsilon$.  \\
  Accept if $\mu f\left( \mu x \right) \cdot g\left( y \right) = f\left(z \cdot x c^{-1}\left( y \right)  \right)$

\end{algorithm}


\subsection{2.a.} Let $f = \Chi{i}, g = \Chi{j}$ and $j = c(i)$. In that case it holds that: 

\begin{equation*}
  \begin{split}
    \mu f\left( \mu x \right) \cdot g\left( y \right)  &= \mu \Chi{i}\left( \mu x \right)\Chi{j}\left( y \right) = \mu^{2}x_{i}y_{j} = x_{i}y_{j} \\ 
    f\left(z \cdot x c^{-1}\left( y \right)  \right) & = \Chi{i}\left( zx c^{-1}(y) \right) = z_{i}x_{i}y_{j} 
  \end{split}
\end{equation*}
Thus, the test pass only if $z_{i} = 1$ and it given that this event happens with probability $1-\varepsilon$. 

\subsection{2.b.} 
Denote by $\alpha_{I} \in \mathbb{R}$ and $\beta_{I} \in \mathbb{R}$ the coefficients of $f,g$ over the character $\Chi{I}$.  
\begin{equation*}
  \begin{split}
    & \expp{\mu f\left( \mu x \right) \cdot g\left( y \right)f\left(z \cdot x c^{-1}\left( y \right)  \right)} \\
    & = \sum_{I,J,K}\alpha_{I}\alpha_{K}\beta_{J}\expp{ \mu \Chi{I}\left( \mu x \right)\Chi{J}\left( y \right) \Chi{K}\left( zx c^{-1}(y) \right) } \\
    & = \sum_{I,J,K}\alpha_{I}\alpha_{K}\beta_{J}\expp{\expp{ \mu \Chi{I}\left( \mu x \right)\Chi{J}\left( y \right) \Chi{K}\left( zx c^{-1}(y) \right)|\mu}} \\ 
    & = \sum_{I,J,K}\alpha_{I}\alpha_{K}\beta_{J}\frac{1}{2}\left( \left( - 1 \right)^{|I|+1}  + 1\right) \expp{  \Chi{I}\left(  x \right)\Chi{J}\left( y \right) \Chi{K}\left( zx c^{-1}(y) \right) }  
  \end{split}
\end{equation*}

Thus, all the elements in which $|I|$ is even contribute zero for the exception. Now, let's apply the conditional expectation formula again conditioning over $I,J,K, x,y$:   
\begin{equation*}
  \begin{split}
    &  = \sum_{I,J,K, |I| \text{is odd} }\alpha_{I}\alpha_{K}\beta_{J} \expp{\expp{ \Chi{I}\left(  x \right)\Chi{J}\left( y \right) \Chi{K}\left( zx c^{-1}(y) \right) | I,J,K }} \\  
    &  = \sum_{I,J,K, |I| \text{is odd} }\alpha_{I}\alpha_{K}\beta_{J} \expp{ \sum_{ \xi = 0}^{|K|}{ { |K| \choose \xi } \left( -\varepsilon \right)^{\xi} \left( 1 - \varepsilon \right)^{|K|- \xi} \Chi{I}\left(  x \right)\Chi{J}\left( y \right) \Chi{K}\left( x c^{-1}(y) \right) }} \\  
    &  = \sum_{I,J,K, |I| \text{is odd} }\alpha_{I}\alpha_{K}\beta_{J} \expp{ \left( 1 -2 \varepsilon \right)^{|K|} \Chi{I}\left(  x \right)\Chi{J}\left( y \right) \Chi{K}\left( x c^{-1}(y) \right) }   
  \end{split}
\end{equation*}
Let us denote by $C^{-1}(K)$ the indices $C^{-1}(K) = \{ j : \exists i \in K, c(i) = j \}$. Then we get that:  
\begin{equation*}
  \begin{split}
    \Chi{K}\left( x c^{-1}(y) \right) = \prod_{i \in K}{x_{i}y_{c_{i}}} =  \Chi{K}\left( K \right) \Chi{C^{-1}(K)}\left( y  \right)
  \end{split}
\end{equation*} Recall that for any $I,J \subset [n]$ it holds that: 
\begin{equation*}
  \begin{split}
    \expp{ \Chi{I}(x)\Chi{J}(x) } = \expp{ \Chi{I \Delta J}(x) } = \mathbf{1}_{ I = J }
  \end{split}
\end{equation*}
And therefore the above can be simplified into: 
\begin{equation*}
  \begin{split}
    \sum_{|I| \text{is odd} }{\alpha_{I}^{2}\beta_{C^{-1}(I)}  \left( 1 -2 \varepsilon \right)^{|I|}}   
  \end{split}
\end{equation*}

\subsection{2.c} 
First let's bound from below the excpection by the given that $f$ and $g$ pass the test with probability at least $\frac{1}{2} + \delta$:

\begin{equation*}
  \begin{split}
    & \expp{\mu f\left( \mu x \right) \cdot g\left( y \right)f\left(z \cdot x c^{-1}\left( y \right)  \right)} \\ 
    & = \prb{\mu f\left( \mu x \right) \cdot g\left( y \right) = f\left(z \cdot x c^{-1}\left( y \right)  \right)} -  \prb{\mu f\left( \mu x \right) \cdot g\left( y \right) \neq f\left(z \cdot x c^{-1}\left( y \right)  \right)} \\ 
   & \ge \frac{1}{2}+\delta - \left( \frac{1}{2} - \delta \right) = 2\delta
  \end{split}
\end{equation*}
Thus in total the inequality of the above section becomes: 
 \begin{equation*}
   \begin{split}
     \sum_{|I| \text{is odd} }{\alpha_{I}^{2}\beta_{C^{-1}(I)}  \left( 1 -2 \varepsilon \right)^{|I|}} \ge 2\delta 
   \end{split}
 \end{equation*}
Using Cauchy-Schwartz to bound from above, we obtain: 
\begin{equation*}
   \begin{split}
     & \left( \sum_{|I| \text{is odd} }{\alpha_{I}^{2}\beta_{C^{-1}(I)}  \left( 1 -2 \varepsilon \right)^{|I|}} \right)^{2}  \le  \sum_{|I| \text{is odd} }{ \alpha_{I}^{2}  } \cdot  \sum_{|I| \text{is odd} }{\alpha_{I}^{2}\beta_{C^{-1}(I)}^{2}  \left( 1 -2 \varepsilon \right)^{2|I|}}
   \end{split}
 \end{equation*}

\begin{equation*}
  \begin{split}
    & \sum_{|I| \text{is odd} }{\alpha_{I}^{2}\beta_{C^{-1}(I)}  \left( 1 -2 \varepsilon \right)^{|I|}}  \le \frac{1}{4} \sum_{|I| \text{is odd}, (1-2\varepsilon)^{|I|} < \frac{1}{4}}{\alpha_{I}^{2}\beta_{C^{-1}(I)}}  + \sum_{|I| \text{is odd}, (1-2\varepsilon)^{|I|} \ge \frac{1}{4} }{\alpha_{I}^{2}\beta_{C^{-1}(I)}  \left( 1 -2 \varepsilon \right)^{|I|}}  
   \end{split}
\end{equation*}
Observes that for any subset $S \subset [n]$ it holds that: 

\begin{equation*}
  \begin{split}
    & \sum_{|I| \in S }{\alpha_{I}^{2}\beta_{C^{-1}(I)}} \le \sum_{|I| \subset [n] }{\alpha_{I}^{2}\beta_{C^{-1}(I)}} \le \\ 
    & \frac{1}{2} \left( \sum_{|I| \subset [n] }{\alpha_{I}^{4}} + \sum_{|I| \subset [n] }{\beta_{I}^{2}}   \right) = \frac{1}{2} \left(|f|_{4}^{4} + |g|_{2}^{2} \right) = 1
  \end{split}
\end{equation*}
In addition: 
\begin{equation*}
  \begin{split}
   & \sum_{|I| \text{is odd}, (1-2\varepsilon)^{|I|} \ge \frac{1}{4} }{\alpha_{I}^{2}\beta_{C^{-1}(I)}  \left( 1 -2 \varepsilon \right)^{|I|}} \\
  \le  & \sum_{|I| \text{is odd}, (1-2\varepsilon)^{|I|} \ge \frac{1}{4}, \beta_{C^{-1}(I)} \ge 0  }{\alpha_{I}^{2} \beta_{C^{-1}(I)}  \left( 1 -2 \varepsilon \right)^{|I|}} \\
  \le  &  \sum_{|I| \text{is odd}, (1-2\varepsilon)^{|I|} \ge \frac{1}{4}, \beta_{C^{-1}(I)} \ge 0  }{ \frac{1}{4}\left(|\alpha_{I}|^{2} +  \beta_{C^{-1}(I)}^{2} |\alpha_{I}|^{2}\left( 1 -2 \varepsilon \right)^{2|I|}\right) } \\ 
  \le & \frac{1}{4} \left( 1  + \max \beta_{C^{-1}(I)} |\alpha_{I}| \left( 1 - 2\varepsilon \right)^{2|I|} \cdot \sum_{J}a_{J}\beta_{C^{-1}(J)} \right) \\
  \le & \frac{1}{4} \left( 1  + \max \beta_{C^{-1}(I)} |\alpha_{I}| \left( 1 - 2\varepsilon \right)^{2|I|}  \right) \\
  \end{split}
\end{equation*}

So the inequality becomes:  

\begin{equation*}
  \begin{split}
    & \le \frac{1}{4} +  \sum_{|I| \text{is odd}, (1-2\varepsilon)^{|I|} \ge \frac{1}{4} }{\alpha_{I}^{2}\beta_{C^{-1}(I)}  \left( 1 -2 \varepsilon \right)^{|I|}} \\
    & \le \frac{1}{4} +  \max_{I} \alpha_{I}^{2}\beta_{C^{-1}(I)}  \sum_{|I| \text{is odd}, (1-2\varepsilon)^{|I|} \ge \frac{1}{4} }{|\alpha_{I}|  \left( 1 -2 \varepsilon \right)^{|I|}} \\ 
    & \le \frac{1}{4} + 
  \end{split}
\end{equation*}
So it left to compute the expectation $ \expp{ \Chi{I}\left( x \right)\Chi{J}\left( y \right) \Chi{K}\left( x c^{-1}(y) \right) }$ and observes that if $c^{-1}(y)$ has no intersection with $K$. Define by $C(K)$ all the indices $i$ such that there exist $ k \in K$ for which $y_{c_{k}} = y_{i}$. 
\begin{equation*}
  \begin{split}
    \expp{\prod_{i \in I}{ x_{i}} \prod_{j \in J}{ y_{j}} \prod_{k \in K }{ x_{k}\cdot y_{c_{k}}} } = \expp{\prod_{i \in I \Delta K }{ x_{i}} \prod_{j \in J \Delta C(K) }{ y_{j}}}
  \end{split}
\end{equation*}
\begin{proof}
\end{proof}

\subsection{Ex 3. The label cover problem.} 
\paragraph{The reduction.} Let $\braket{G=(V,E), \{ c_{e} \} }$ be a given instance of the Label cover problem. For each edge $e = \{v,u\} \in E$ define the test $T_{\varepsilon}\left( c_{e} \right)$ as defined above , Thus in total we define a $|E|$ tests, denote them by $T$. Consider the language $L$ such that a test collection $T$ is in $L$ if there exists function $f \times V$ such that the probability:  
\begin{equation*}
  \begin{split}
    \prb{T_{\varepsilon}(c_{ \{ v,u\} }) \text{ accepts on } f_{v},f_{u} } \ge \frac{1}{2} + \delta
  \end{split}
\end{equation*}
For every $\{v, u\} \in E$. A probabilistic verifier takes a candidate $f\times V : \pm  \times V \rightarrow \pm$, picks a random edge $e \in E$ and then check $T_{\varepsilon}\left( c_{e} \right)$ over the functions $f_{v},f_{u}$.    


%And notice that on binary field the test is equivalence for picking a random equation from the liner system in which each equation contains exactly tree variables.  
%vertex $v \in V$ define a variable $\xi_{v} \in \mathbb{F}_{2}^{|\Sigma|}$ and for any when we think on the functions $f,g : \pm^{|\Sigma|} \rightarrow \pm $ as the 'witness'/'input' given by the 'prover'/'user'
%For any $x,y,\mu, z$ 
\paragraph{Compeletnce. } Suppose that $\braket{G=(V,E), \{ c_{e} \} } \in (\mu,1)$-Label Cover then either there exists a labeling $A$ such that $c_{vu}(A(v)) = A_{u}$ for any $\{v,u\}\in E$ or that any labeling satisfies at most $\mu$ constraints. For compeletnce, let's assume the first case, and denote by $A$ the satisfying labeling. Consider the function $f \times V : \pm \times V \rightarrow \pm$ defined as follow: $f_{v} = \Chi{A(v)}$, So by the first section of part 2 we have that any of the test accepts with probability $1-\varepsilon$. That it, as we pick a test uniformly random, the existences of satisfying labeling for the label cover problem give a function that pass the test with probability $1-\varepsilon$. 
%\begin{equation*}
%  \begin{split}
%    & A(v) = \Chi{i} \\ 
%    & A(u) = \Chi{j} \\ 
%    & j = P_{uv} i  
%  \end{split}
%\end{equation*}
\paragraph{Soundness.} \ctt{Wrong proof.} Now, assume the second case, namely that any labeling satisfies at most $\mu$ constraints. Also assume through contridiction that there exists an assigment that satisfies more than $\frac{3}{4}+\delta$ equations. Therefore on more than $\frac{1}{4}$ of the tests $f$ pass with probablility at least: $\frac{1}{4}\cdot 1 + \frac{3/4}p   \ge \frac{3}{4} + \delta$ $\Rightarrow p \ge \frac{2}{3} +\frac{4}{3} \delta$. (\ctt{Wrong argument}) So ..  
\section{Part 3.}

\paragraph{Label cover when the aleph-bet depends on the vertex.} Instead of showing reduction into the general label cover we will show a reduction to a similar problem in which vertices can have an additional restriction on the valid charters that one can sets on. In formal, we will say that $\braket{G, \{ \Sigma_{v} : v \in V \}, \{c_{e} : e \in E \}} $ instance of Generalized-Label-Cover if there is an labeling $A : V \rightarrow \Sigma$ such that for any $\{v,u\} \in E$ it holds that $c_{e}A(v) = A(u)$ and in addition for any $v \in V$ we have that $A(v) \in \Sigma_{v} \subset \Sigma$.  

\paragraph{The reduction.} Define the Bipartite graph $G = (L,R,E)$. Associate the left vertices with the variables and the right with the closures. Define $\{u,v\}$ to be an edge if the literal which associate with the vertex $u$ is in the closure associate with vertex $v$. For the alphabet take $\Sigma = \mathbb{Z}_{2}^3$. For any right vertex $v\in R$ define $\Sigma_{v}$ be all the assignments for which the $v$-closures is satisfied and for any left vertex $u$ define $\Sigma_{u} = \{ \left( 1 , 0 , 0 \right), \left( 0 , 0, 0 \right) \}$. Finally define $c_{e}$ for $ e = \left\{ v \in R, u \in L \right\}$ to be the projection of $\sigma \in \Sigma$, setted on $v$, to the coordinate corresponding with $u$. For example, assume that $v$ associate with $x\vee y \vee z $ and let $u$ be the vertex associate with $x$, And assume that $A(v) = (1,0,1)$ , then $c_{e}A_{v} = (1,0,0)$.           

%For the right vertices, consider the $3!$ permutations of the closures, and associate for any of them a right vertex. For example, consider the closure $ x\vee y \vee z$, then associate a right vertex with the closures $x \vee y \vee z$,  $y \vee z \vee x$, $z \vee x \vee y$, $y \vee x \vee z$ and etc.

%For the edges, connect between any closure on the right an edge between it and the left vertices which associate with the first terminal on the closure.Notice that the right degree of the graph is $1$ while the left degree of the vertex associated with terminal $x$ is:
%\begin{equation*}
%  \begin{split}
%     2 \times \text{ number of closures containing } x 
%  \end{split}
%\end{equation*}
%The permeations on the edges defined as follow: Let $x$ be variable, and $\psi$ a closure in which $x$ is the first terminal. Sets the permeation of the edges as following, if $x$ appears in his positive form, namely $\psi = x \vee .. $ then set on the edge $\left\{ x, \psi \right\}$ the identity permutation otherwise set the flipping permutation. 
%

\paragraph{Compeletnce. } Suppose that $\varphi \in \text{E3-CNF-SAT}$ and let $x \in \mathbb{F}_{2}^{*}$ be the assignment that satisfies $\varphi$. That it, $\varphi\left( x \right) = \mathbf{True}$. Let $A$ be the labeling that sets for any vertex on the left the bit matched to that literal by $x$ follows by zeros padding. And for any right vertex the triple of the bits corresponding to literals involving in the associated closure. By the fact that $x$ satisfies $\varphi$ any closure in $\varphi$ is satisfied by $x$ and therefore each of the right vertices (closures) see on his local view a character of $\Sigma_{v}$. In addition by the definition of the construction any pair of connected vertices satisfies the edge restriction. 

\paragraph{Soundness.} Suppose that $\varphi \in \text{E3-CNF-SAT}$ but not satisfiable and $\braket{G, \{ \Sigma_{v} : v \in V \}, \{c_{e} : e \in E \}} $ is an instance obtained by the reduction above. Assume throawds contradiction that there exists labeling $A$ such that more than $\mu^{\prime}= 6\mu$ of the restriction $\{c_{e}\}$ are satisfied. 

Define by $\alpha_{i}$ to be the number of right vertices which satisfy exactly $i$ edges, that it, 
\begin{equation*}
  \begin{split}
    \alpha_{i} = \left| \left\{ | \left\{ c_{e}A\left( v \right) = A\left( u \right) : u \in L \right\} | = i : v \in R   \right\} \right| 
  \end{split}
\end{equation*}

\begin{claim}
  For any labeling $A$ such that $\alpha_{3} \ge \mu$ there exists an assignment $x \in \mathbb{F}_{2}^{*}$ satisfies at least $\mu$ portion of the restrictions. 
\end{claim}

\begin{proof}
  The proof is trivial. 
\end{proof}

\begin{claim}
  For any labeling $A$ that satisfy $\xi$ constraints, there exists labeling $A^{\prime}$ such that any constraint that satisfied by $A$ also satisfied by $A^{\prime}$ and in addition $\alpha_{0}=\alpha_{1}=0$. Put it differently, we can assume that $\alpha_{0}=\alpha_{1}=0$.
\end{claim}

\begin{proof}
  Let $v \in R$ be a vertex that satisfies less than two edges. Recall that $\Sigma_{v}$ contains all the triple that satisfy the closure associated with $v$. By the fact that for any 3-CNF closure there is exactly one assignment which does not satisfy it, It follows that $|\Sigma_{v}| = 2^{3}-1 = 7 \ge 2^{2}$. Therefore, we can replace $A(v)$ by a triple that agree with the first two vertices connected to it.     
\end{proof}

Using the above claim we can infer that $\alpha_{2} + \alpha_{3} = |R|$ and in addition $2\cdot \alpha_{2} + 3 \cdot \alpha_{3} \ge \mu^{\prime} \cdot 3|R|$. Thus, $\alpha_{3}\ge \left( 3\mu^{\prime} - 2 \right)|R|$. 
Particularly if $\mu^{\prime} \ge \frac{\mu + 2}{3}$ then $\alpha_{3} \ge \mu|R|$, Combining the claim above we get a contradiction to the fact that $\varphi \in\left( \mu,1 \right)$ gap-3E-CNF-SAT and not satisfiable. 

%\begin{claim}
%  Let $A$ an assignment such that satisfy $\xi$ relations and it's support on the right side is at most $1 - \alpha$ then flipping assignment $ 1 + A$ also satisfy $\xi$ relations, but has at least $\alpha$ support on the right side.     
%\end{claim}
%\begin{proof}
%\end{proof}
%
%Suppose that we have an assignment that satisfies $ \ge \mu/3 $ of the closers,  


\end{document}


